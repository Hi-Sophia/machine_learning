

一、人工智能概念

1. 人工智能>机器学习>深度学习

   机器学习流程：数据收集->数据预处理->特征提取->**模型构建**->模型测试->模型部署与整合->迭代优化

   深度学习：是基于传统的**神经网络算法**发展到多隐层的一种算法体现。

2. 参数，超参数：

   参数：模型根据数据**自动学习出的变量**，如深度学习的权重，偏差等

   超参数：**根据经验确定的变量**。深度学习中超参数有：学习速率，迭代次数，层数，每层神经元的个数等等。

3. 模式识别

4. 全连接层：每一个结点都**与上一层的所有结点相连**，用来把前边提取到的特征综合起来。

5. 预测任务

6. 推荐算法

7. 分布式

8. 容错性

9. 协同过滤

二、获取数据与特征工程

1、了解获取数据相关内容

- [x] 数据集、训练集、测试集、验证集
- [x] 离散数据、连续数据
- [x] 特征(feature)、特征向量、样本(Sample)、类标签(Label)
- [x] 递归、迭代、并行
- [x] 字段
- [x] PCA，降维
- 降维的算法有很多，比如奇异值分析(SVD)、主成分分析(PCA)
- PCA的主要思想是将n维特征映射到k维上，这k维是全新的**正交特征**也被称为**主成分**，是在原有n维特征的基础上重新构造出来的k维特征
- PCA的工作就是从原始的空间中顺序地找一组**相互正交的坐标轴**，新的坐标轴的选择与数据本身是密切相关的。其中，第一个新坐标轴选择是**原始数据中方差最大的方向**，第二个新坐标轴选取是**与第一个坐标轴正交的平面中使得方差最大的**，第三个轴是**与第1,2个轴正交的平面中方差最大的**。依次类推，可以得到n个这样的坐标轴
- [x] 分布，主题分布，长尾分布
- [x] 矢量，标量
- [x] 多项式

2、获取数据

- [x] 归一化
- 把数据映射到0～1范围之内处理。主要是为了数据处理方便提出来的。
- 把有量纲表达式变成无量纲表达式，便于不同单位或量级的指标能够进行比较和加权。
- [x] 人工标注
- [x] 特征选择，特征提取
- [x] 正例样本，负例样本
- [x] 类别集合，待分类项
- [x] 序列，向量序列
- [x] 自变量，因变量
- [x] 采样

3、数据处理

- [x] 分词、分词器
- [x] 高维数据投影到低维空间
- [x] 特征提取
- [x] 近似

三、模型训练

1、模型一

- [x] 模型(Model)，参数(Parameter) 
- [x] 训练，预测，分类，回归，聚类
- [x] 目标函数，损失函数（能量函数、风险函数、准则函数）
- [x] 属性集X，目标属性Y
- [x] 梯度：移动的方向。 步长：移动的长度
- [x] 全局最优解，局部最优解
- [x] 准确度，误差，逼近
- [x] 训练速度，解空间搜索（随机搜索，批量随机搜索，网络搜索）
- 训练速度：小球下山速度快慢  
- 解空间搜索：小球下山过程

2、模型

- [x] 簇，聚类中心 

- 簇：按10-20、30-40、50-60岁将人分为不同的群体

- 聚类中心：平均身高、平均体重

- [x] 收敛

- [x] 表征学习

  即特征学习，分为两类：监督学习和无监督学习。允许计算机学习使用特征的同时，也**学习如何提取特征**。

- [x] 监督学习、非监督学习、半监督学习（semi-supervised learning）

  |          | 监督学习                                                     | 非监督学习                                                   | 非监督学习                                                   |
  | -------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
  | 定义     | 用具有某些特征的样本作为训练集，建立一个数学模型并**用已建立的模型来预测未知样本** | 训练集中没有人为的标注的结果，试图学习或者提取数据背后的数据特征 | 如何利用**少量的标注样本**和**大量的未标注样本**进行训练和分类，是**有监督学习和无监督学习的结合 |
  | 常见算法 | 判别式模型： 线性回归、决策树、支持向量机SVM、k近邻、神经网络  <br />生成式模型 ： 隐马尔可夫模型HMM、朴素贝叶斯模型、高斯混合模型GMM、LD | 聚类、降维、文本处理(特征抽取)                               | 半监督分类、半监督回归、半监督聚类、半监督降维               |
  | 使用场景 |                                                              |                                                              | 抗干扰能力弱，仅适合于实验室环境                             |

3、模型三

- [x] 分类器

- [x] 过拟合 欠拟合

- [x] 样本进行加权，权重

  权重：一个参数，将影响放大

- [x] 残差

  真实值与预测值之间的差值

- [x] 真实值 预测值

- [x] Line search

- [x] 计算瓶颈，性能提升

4、模型四

- [x] 超平面

  如果空间是3维的，那么它的超平面是二维平面，而如果空间是二维的，则其超平面是一维线

  超平面一定经过原点

- [x] 规划问题 求极值

- [x] 正则化 ，约束（正则化）， L1产生稀疏模型，惩罚项

- 正则化是为了解决过拟合问题

- 正则化项的引入其实是利用了先验知识，体现了人对问题的解的认知程度或者对解的估计

- 有助于处理 条件数（condition number）不好的情况下矩阵求逆很困难的问题

- 正则化项的引入平衡了偏差（bias)与方差(variance)、拟合能力与泛化能力、经验风险（平均损失函数）与结构风险（损失函数+正则化项）

- 正则化产生了稀疏性（Sparsity），减少了特征向量个数，降低了模型的复杂度

- [x] 在线(online)技术

- [x] 模型参数的线性组合

- [x] 线性边策边界 非线性决策边界

- [x] 相似度，余弦相似度，欧几里得距离